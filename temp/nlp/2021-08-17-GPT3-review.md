---
title:  "[미완성] XLNet: Generalized Autoregressive Pretraining for Language Understanding review"
toc: true
toc_sticky: true
permalink: /project/nlp/XLNet-review/
categories:
  - NLP
  - Paper Review
tags:
  - Language Modeling
  - GPT3
  - TODO
use_math: true
last_modified_at: 2021-08-17
---

## 들어가며

오랜만에 진행하는 NLP paper review이다. 잠시동안 다른 공부를 하게 되었는데, 어찌하다보니 거의 반년이 지나게 되었다. 아직도 리뷰할 paper가 많이 남아있지만, 오랫동안 손을 놓고 있었기 때문에 가장 최근에 핫했던 GPT3에 대해 리뷰해고자 한다. GPT-1과 GPT-2에 대한 리뷰는 아래에서 확인할 수 있다.

- [GPT-1 review 보러가기](/project/nlp/gpt1/)
- [GPT-2 review 보러가기](/project/nlp/gpt2-review/)

본 포스트는 단순 번역이 아니라 적절한 해석과 의역을 섞었음에 주의하라. 본 논문의 원본은 [이곳](https://arxiv.org/pdf/2005.14165.pdf)에서 확인할 수 있다.


## Introduction

최근 몇년간 NLP 시스템에서 pre-trained language representation에 대한 트렌드가 일어났고, **downstream task에 대해 유연하고 task-agnostic**한 방법으로 적용되었다. 즉, 서로 다른 task에 대해 다른 구조를 구하는 것이 아니라 말 그대로 **태스크에 관계없는 구조**를 사용하는 것이다. 이는 다음과 같은 방법으로 이루어진다.

1. word2vec, GloVe와 같은 word vector를 사용하여 single-layer representation을 학습
2. 태스크에 특화된 구조로 삽입
3. (비록 여전히 태스크 특화된 구조에서 사용될지라도) multi-layer RNN과 contextual state를 사용하여 더욱 좋은 representation을 얻음: [Dai and Le, 2015](https://dl.acm.org/doi/10.5555/2969442.2969583), CoVe, [Peters et al., 2018](https://aclanthology.org/D18-1179.pdf)

더욱 최근에는 pre-trained RNN이나 transformer를 이용한 language model이 바로 fine-tuning되어 태스크에 특화된 구조의 필요성을 없애버렸다 (BERT, GPT, ELMo).

이러한 패러다임은 기계독해, QA, textual entailment 등과 같은 많은 어려운 NLP task에서 실질적인 발전을 이끌고, 새로운 구조와 알고리즘에 기반하여 계속해서 진보를 꾀하고 있다 (ALBERT, T5, XLNet, roBERTa).

![image](https://user-images.githubusercontent.com/47516855/126507330-870807b5-65b3-45a5-a943-e878d3551497.png){: .align-center}{: width="700"}

Textual entailment 예시 (2013 한국컴퓨터종합학술대회 (2013/06/26))
{: .text-center}

그러나 이러한 방법론의 주요 한계점은 구조가 태스크에 관계없이 구성되긴 하지만 여전히 태스크에 특화된 데이터셋과 fine-tuning을 필요로 한다는 점이다. 원하는 태스크에 대해 강력한 성능을 보이기 위해서는 일반적으로 태스크와 연관된 엄청나게 많은 데이터셋이 필요하다. 이러한 한계를 없애는 것은 아래의 이유들로 인해 매우 바람직하다고 할 수 있다.

첫번째. 실질적인 이유로, **매번 새로운 태스크에 대해 대량의 라벨링된 데이터 셋을 필요**로 한다는 점이 언어 모델의 적용성을 제한시킨다는 것이다. 애초에 이러한 일을 잘 하는 것이 language modeling인데, 그러면 LM이 필요할 이유가 없지 않을까? 문법 교정, 요약된 정보를 통해 문서를 생성한다던가, 짧은 이야기에 대해 비평하는 등 자연어 처리에 대한 태스크는 그 범위가 매우 넓다고할 수 있다. 이렇게 많ㅇ느 태스크에 대해 많은 량의 supervised training dataset을 모으는 것은 어렵다고 할 수 있고, 이는 특히 모든 새로운 태스크에 대해 빠짐없이 적용되야 할 것이다.

두번째로, 근본적으로 **모델의 표현력(용량)과 학습 분포의 narowness로 인해 학습데이터에서 spurious correlation을 갖을 확률이 높아진다**고 할 수 있다. 이는 특히 pre-training + fine-tuning 조합에서 문제가 되는데, 이는 이러한 패러다임이 pre-training 단계에서 정보를 많이 배우도록 크게 설계되어 있지만 매우 좀은 task distribution에서 fine-tuning하기 때문이다. 예를 들어 [Hendriycks et al., 2020](https://arxiv.org/abs/2004.06100)는 큰 모델일수록 필연적으로 out-of-distribution을 더 잘 일반화하는 것은 아니라는 것을 관측하였다. 게다가 특정 벤치마크에 대한 fine-tuned model의 성능이 실제로는 인간과 비슷한 수준임에도 더욱 과장하여 보고될 수 있다.




## 2

Sparse Transformer는 Transformer의 self-attention내 $O(N^2)$연산을 $O(N \sqrt(N))$으로 줄여 긴 길이를 갖는 데이터(비디오, 이미지, 소리)에도 쉽게 적용할 수 있도록 만든 구조이다. 

기존의 Transformer는 각 output을 계산할 때 이보다 낮은 sequence만을 이용하여 attention을 계산하였다. 그러나 Sparse Transformer는 input position의 subset만을 이용한다. $N$개의 input 중 $\sqrt(N)$을 고르는 것처럼 상대적으로 작은 subset을 골른다면 매우 긴 sequence에 대해서도 attention을 계산하는 것이 tractable해질 것이다. 

## 3 Results

Power-law behavior

#### 3.1.1 Language Modeling

GPT3에서는 zero-shot을 통해 Penn Tree Bank(PTB)에 대한 perplexity를 계산하여 보고한다. 본래 PTB는 POS를 위한 데이터셋이지만 character/word-level LM을 위해서도 널리 이용되는 데이터셋이다. GPT3에서는 데이터 오염의 문제로 PTB를 사용했다고 밝히고 있다.

#### 3.1.2 LAMBADA

또한, LAMBADA에서 예전부터 겪어왔던 문제를 해결함으로서 few-show learning의 유연함을 증명하였다. LAMBADA 데이터셋을 완성시키는 것은 항상 문장의 마지막인데 일반적인 language model은 이를 알 방법이 없다. 따라서 정답뿐만 아니라 다른 **문단 내 유효한 단어들**에도 확률을 부여하게 된다. 이러한 문제는 stop-word filter를 통해 "연속적인" 단어를 제거함으로서 부분적으로 해결하게 되었다. Few-show setting에서는 대신, task의 "frame"을 cloze-test로 줄 수 있게되고, LM으로 하여금 example로부터 오직 한 단어만 완성하도록 만든다.


### 3.8 NLI

**Natural Language Inference (NLI)**는 **두 문장 사이의 관계를 이해하는 능력을 측정**한다. 이 작업은 두 개 혹은 세 개의 클래스를 분류하는 문제로 구성되며, 모델은 두번째 문장이 논리적으로 첫번째 문장 뒤에 올 수 있는지, 이에 반대되는지, 아니면 참인지 (자연스러운지) 분류하게 된다. SuperGLUE는 NLI 데이터셋인 **RTE (Textual Entailment Recognition)**를 포함하고 있으며, 이는 NLI의 이진분류 버전이다. GPT-3에서 가장 큰 버전만이 RTE에서 확실하게 어떠한 세팅에서도 임의의 확률로 찍는 것보다 더 나은 성능을 보였으며 (56%), few-shot learning에서는 fine-tuned BERT Large와 비슷한 성능을 내었다. 이에 그치지 않고 최근 소개된 Adversarial Natural Language Inference (ANLI) 데이터셋에도 평가를 진행하였다. ANLI는 적대적으로 




{: .text-center}

---
title:  "내 멋대로 하는 Retrieval-Augmented Generation for Large Language Models review"
toc: true
toc_sticky: true
categories:
  - NLP
  - Paper Review
tags:
  - Instruction Tuning
  - Large Language Model
use_math: true
last_modified_at: 2024-01-04
---

## 들어가며

다음은 [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997v4)의 section 일부분 중 내가 필요한 내용만을 발췌하여 정리한 것이다.


- LLaMAINDEX

Prompt Compression:
- TODO: Recomp [Xu et al., 2023a] addresses this by training compressors at different granularities, while Long Context [Xu et al., 2023b] and "Walking in the Memory Maze" [Chen et al., 2023a] design summarization techniques to enhance LLM’s key information perception, particularly in dealing with extensive contexts.


1) How can we achieve accurate semantic representations?
4.1 Enhancing Semantic Representations

Chunk optimization
- sliding window technology: enabling layered retrieval by merging globally related information across multiple retrieval processes.
  - TODO: 확인해보기
- small2big: utilizes small text blocks during the initial search phase and subsequently provides larger related text blocks to the language model for processing.
    - TODO: 확인해보기
- metadata filtering technique: leverages document metadata to enhance the filtering process
  - TODO: 구체적인 예시 확인
- graph indexing technique: transforms entities and relationships into nodes and connections, significantly improving relevance, particularly in the context of multi-hop problems.
  - TODO: 그래프 인덱싱 확인해보기

Fine-tuning Embedding Models
- Embedding model: AngIE, Voyage, BGE
- Domain Knowledge Fine-tuning: 별거없음
- Fine-tuning for Downstream Tasks:
  - PROMPTAGATOR [Dai et al., 2022] utilizes the LLM as a few-shot query generator to create task-specific retrievers, addressing challenges in supervised fine-tuning, particularly in data-scarce domains.
  - LLM-Embedder [Zhang et al., 2023a], exploits LLMs to generate reward signals for data across multiple downstream tasks.
- The retriever is fine-tuned with two types of supervised signals: hard labels for the dataset and soft rewards from the LLMs. 
- This dual-signal approach fosters a more effective fine-tuning process, tailoring the embedding model to diverse downstream applications.


4.2 Aligning Queries and Documents
2) What methods can align the semantic spaces of queries and documents?

it is crucial to align the semantic space of the user’s query with those of the documents. This section introduces two fundamental techniques aimed at achieving this alignment.

Query Rewriting
- Query2Doc and ITER-RETGEN leverage LLMs to create a pseudo-document by combining the original query with additional guidance [Wang et al., 2023c, Shao et al., 2023].
- HyDE constructs query vectors using textual cues to generate a “hypothetical” document capturing essential patterns [Gao et al., 2022].
- RRR introduces a framework that reverses the traditional retrieval and reading order, focusing on query rewriting [Ma et al., 2023a].
- STEP-BACKPROMPTING enables LLMs to perform abstract reasoning and retrieval based on high-level concepts [Zheng et al., 2023]. Additionally, the multi-query retrieval method utilizes LLMs to generate and execute multiple search queries simultaneously, advantageous for addressing complex problems with multiple sub-problems.

Embedding Transformation
- LlamaIndex [Liu, 2023] exemplifies this by introducing an adapter module that can be integrated following the query encoder. This adapter facilitates fine-tuning, thereby optimizing the representation of query embeddings to map them into a latent space that is more closely aligned with the intended tasks.
- The challenge of aligning queries with structured external documents, particularly when addressing the incongruity between structured and unstructured data, is addressed by SANTA [Li et al., 2023d].


4.3 Aligning Retriever and LLM

3) How can the retriever’s output be aligned with the preferences of the Large Language Model?

Fine-tuning Retrievers
- AAR [Yu et al., 2023b] introduces supervisory signals for a pre-trained retriever using an encoder-decoder architecture.
- REPLUG [Shi et al., 2023] utilizes a retriever and an LLM to calculate the probability distributions of the retrieved documents and then performs supervised training by computing the KL divergence.
- UPRISE [Cheng et al., 2023a] also employs frozen LLMs to fine-tune the prompt retriever. Both the LLM and the retriever take prompt-input pairs as inputs and utilize the scores provided by the LLM to supervise the retriever’s training, effectively treating the LLM as a dataset labeler.
- Atlas [Izacard et al., 2022] proposes four methods of supervised fine-tuning embedding models:
  - Attention Distillation. This approach employs cross-attention scores generated by the LLM during output to distill the model’s knowledge.
  - EMDR2. By using the Expectation-Maximization algorithm, this method trains the model with retrieved documents as latent variables.
  - Perplexity Distillation directly trains the model using the perplexity of generated tokens as an indicator.
  - LOOP. This method presents a novel loss function based on the impact of document deletion on LLM prediction, offering an efficient training strategy to better adapt the model to specific tasks.

Adapters
Fine-tuning models may present challenges, such as integrating functionality through an API or addressing constraints arising from limited local computational resources.
- PRCA trains the adapter through a context extraction phase and a reward-driven phase. The retriever’s output is then optimized using a token-based autoregressive strategy [Yang et al., 2023b].
- RECOMP introduces both extractive and generative compressors for summary generation. These compressors either select relevant sentences or synthesize document information, creating summaries tailored to multi-document queries [Xu et al., 2023a].
- PKG introduces an innovative method for integrating knowledge into white-box models via directive finetuning [Luo et al., 2023].


5.1 Post-retrieval with Frozen LLM
Information Compression
- information extractor: PRCA [Yang et al., 2023b], RECOMP [Xu et al., 2023a]
- reduce the # documents: Filter-Reranker [Ma et al., 2023b]

Reranking: pivotal in optimizing the document set retrieved from the retriever

FIXME: 구체적인 방법이 없음

5.2 Fine-tuning LLM for RAG
The optimization of the generator aims to ensure that the generated text is both natural and effectively leverages the retrieved documents to better meet the user’s query needs.

General Optimization Process
FIXME: 구체적인 방안 필요

Self-Mem [Cheng et al., 2023b], a traditional training process is employed, where given the input x, relevant documents z are retrieved (selecting Top-1 in the paper), and after integrating (x, z), the model generates the output y. The paper utilizes two common paradigms for fine-tuning, namely Joint-Encoder and Dual-Encoder [Arora et al., 2023, Wang et al., 2022b, Lewis et al., 2020, Xia et al., 2019, Cai et al., 2021, Cheng et al., 2022].
- Joint-Encoder
  - encoder-decoder 구조
  -  the encoder initially encodes the input
  - the decoder, through attention mechanisms, combines the encoded results to generate tokens in an autoregressive manner
- DualEncoder
  - the system sets up two independent encoders
  - each encoder encoding the input (query, context) and the document, respectively
  - The resulting outputs undergo bidirectional cross-attention processing by the decoder in sequence.
  
Both architectures utilize the Transformer [Vaswani et al., 2017] as the foundational block and optimize with Negative Log-Likelihood loss.

Utilizing Contrastive Learning
This traditional method can lead to ”exposure bias,” where the model is only trained on individual, correct output examples, thus restricting its exposure to a range of possible outputs cite sequence.
This limitation can hinder the model’s real-world performance by causing it to overfit to the particular examples in the training set, thereby reducing its ability to generalize across various contexts.

- graph-text contrastive learning (SURGE [Kang et al., 2023]): produce a range of plausible and coherent responses so that reducing overfitting and strengthening the model’s ability to generalize
- retrieval engaged with structured data (SANTA [Li et al., 2023d]): a tripartite training regimen to effectively encapsulate both structural and semantic nuances.
  - TODO: 확인해보기

## 6. Augmentation in RAG

To build a good RAG system, where the augmentation part is key, three critical questions need to be considered:
- What to retrieve?
- When to retrieve?
- How to use the retrieved content?

### 6.1 RAG in Augmentation Stages

Retrieval augmentation can be performed during the pre-training, fine-tuning, and inference stages, which determines the degree of parameterization of external knowledge and corresponds to different computational resources required.

#### Pre-training Stage

The benefits of augmented pre-training include a robust foundational model that outperforms standard GPT models in perplexity, text generation quality, and task-specific performance, all while utilizing fewer parameters. This method is particularly adept at handling knowledge-intensive tasks and facilitates the development of domain-specific models through training on specialized corpora.

Nonetheless, this approach faces challenges such as the necessity for extensive pre-training datasets and resources, as well as diminished update frequencies with increasing model sizes. Despite these hurdles, the approach offers significant advantages in model resilience. Once trained, retrieval-enhanced models can operate independently of external libraries, enhancing generation speed and operational efficiency. The potential gains identified render this methodology a compelling subject for ongoing investigation and innovation in artificial intelligence and machine learning.

RETRO

TODO: 읽어보기

RETRO [Borgeaud et al., 2022] leverages retrieval augmentation for large-scale pre-training from scratch, achieving a reduction in model parameters while surpassing standard GPT models in terms of perplexity. RETRO distinguishes itself with an additional encoder designed to process features of entities retrieved from an external knowledge base, building on the foundational structure of GPT models.

#### Fine-tuning Stage

- FIXME: LLM만으로는 힘든지 궁금

The main goal of fine-tuning the retriever is to improve the quality of semantic representations, achieved by directly fine-tuning the Embedding model using a corpus [Liu, 2023].

Fine-tuning generator can result in outputs that are more stylized and customized. On one hand, it allows for specialized adaptation to different input data formats.

By synergistically fine-tuning both the retriever and the generator, we can enhance the model’s generalization capabilities and avoid overfitting that may arise from training them separately.
However, joint fine-tuning also leads to increased resource consumption.
RA-DIT [Lin et al., 2023] presents a lightweight, dual-instruction tuning framework that can effectively add retrieval capabilities to any LLMs.
The retrieval-enhanced directive fine-tuning updates the LLM, guiding it to make more efficient use of the information retrieved and to disregard distracting content.




![Fig.1-add-caption-here]({{site.url}}{{site.baseurl}}/assets/posts/nlp/){: .align-center}{: width="600"}

![Caption](URL){: .align-center}{: width="600"}


`{: .notice--info}`는 추가적인 정보를 적을 때 사용한다.
{: .notice--info}

`{: .notice--warning}`는 추후 살펴볼 내용을 적는다.
{: .notice--warning}

`{: .notice--warning}`는 잘 모르는 것을 적는다.
{: .notice--warning}

\[[348][348]\]

[28]: https://arxiv.org/abs/2110.08207
[67]: https://arxiv.org/abs/2109.01652
[69]: https://arxiv.org/abs/2210.11416
[88]: https://aclanthology.org/2022.emnlp-main.340/
[94]: https://aclanthology.org/2023.acl-long.891/
[95]: https://arxiv.org/abs/2212.12017
[143]: https://arxiv.org/abs/2212.10560
[145]: https://arxiv.org/abs/2106.09685
[166]: https://aclanthology.org/2022.acl-long.244/
[168]: https://aclanthology.org/2023.findings-acl.558/
[342]: https://arxiv.org/abs/2303.10475
[345]: https://arxiv.org/abs/2301.13688
[348]: https://arxiv.org/abs/2308.06259
[349]: https://arxiv.org/abs/2305.11206
[350]: https://arxiv.org/abs/2307.08701
[351]: https://arxiv.org/abs/2306.02707
[352]: https://github.com/RUC-GSAI/YuLan-Chat
[353]: https://arxiv.org/abs/2306.04751
[396]: https://aclanthology.org/2021.acl-long.353/
[397]: https://aclanthology.org/2021.emnlp-main.243/
[399]: https://aclanthology.org/2023.emnlp-main.319/
[406]: https://arxiv.org/abs/2303.10512
[407]: https://arxiv.org/abs/2303.10512
[409]: https://arxiv.org/abs/2303.16199